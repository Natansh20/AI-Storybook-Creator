{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "TD4ByKgc1Rmz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lvGw5_snuTl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install diffusers gradio openai==0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Setup"
      ],
      "metadata": {
        "id": "55PPObCt1n7g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RgjXnD0oxg8"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusion3Pipeline\n",
        "import torch\n",
        "import transformers\n",
        "import gradio as gr\n",
        "from huggingface_hub import login, InferenceClient\n",
        "import openai\n",
        "\n",
        "openai.api_key = 'OPENAI_API_KEY'\n",
        "login(token='HF_ACCESS_KEY')\n",
        "\n",
        "pipe = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3-medium-diffusers\", text_encoder_3=None, tokenizer_3=None,  torch_dtype=torch.float16).to('cuda')\n",
        "\n",
        "def generate_image_from_text(text):\n",
        "    image = pipe(text, num_inference_steps=28).images[0]\n",
        "    return image\n",
        "\n",
        "\n",
        "def create_storybook(topic):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a great story writer. You write creative and intriguing story based on the given topic. Your sentences will be used to generate a story book so create informative sentences.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Generate a short story on {topic}.\"},\n",
        "        ]\n",
        "    )\n",
        "    story = response['choices'][0]['message']['content']\n",
        "    # story = response.choices[0].message.content\n",
        "    story_parts = story.split(\". \")\n",
        "\n",
        "    images = []\n",
        "    for part in story_parts:\n",
        "        if part.strip():  # Avoid empty strings\n",
        "            image = generate_image_from_text(part)\n",
        "            images.append(image)\n",
        "\n",
        "    return story, images\n",
        "\n",
        "def interface_phase():\n",
        "  gr.Interface(fn = create_storybook, inputs=\"text\", outputs=[\"text\",\"gallery\"]).launch(debug = True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interface_phase()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TuezaKIZzQYj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}